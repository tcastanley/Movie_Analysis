{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**These days when a new movie is being released, it isn't a question of IF it will be released in another country, but rather HOW MANY other countries? The question we aim to analyze for Microsoft Entertainment Studios is:**\n",
    "\n",
    "**Are movies that are released in more countries more profitable?**\n",
    "\n",
    "**The findings in this notebook will show that the answer to that question is in fact: yes. This notebook will walk step-by-step through the importing, cleaning, exploration, and visualization processes undertaken to try and answer Microsoft's question and help inform strategic business decisions going forward.**\n",
    "\n",
    "**The data being analyzed are from two sources: IMDB country data per movie and Box Office Mojo revenue and budget information. These datasets have been saved into an SQL database previously and will be imported into this notebook further down.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleaning & Converting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Drop 'None' types from the region feature & check the unique values.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T02:10:35.149181Z",
     "start_time": "2020-06-22T02:10:35.086322Z"
    },
    "scrolled": true
   },
   "source": [
    "df_title_region = df_title_region.dropna()\n",
    "df_title_region['region'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We noticed that there were different types of country codes in this list. This led to more research to see how one could check that these were all accurate. We found the |pycountry| library, installed it, then imported it below.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T02:10:40.133285Z",
     "start_time": "2020-06-22T02:10:40.130339Z"
    }
   },
   "source": [
    "import pycountry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T02:10:45.344730Z",
     "start_time": "2020-06-22T02:10:45.199424Z"
    }
   },
   "source": [
    "def alpha_code_check(value):\n",
    "    \"\"\"This function takes in a an alpha code country value, determines its\n",
    "    classification, and returns that result.  This function is meant to be \n",
    "    mapped along a DataFrame series.\n",
    "    \n",
    "    Returns:\n",
    "    Assigned categorical value\n",
    "    \n",
    "    Example:\n",
    "    df['region'].map(lambda x: alpha_code_check(x))\"\"\"\n",
    "\n",
    "    if len(value) == 2:\n",
    "        value = 'aplha_2'\n",
    "        return value\n",
    "    elif len(value) == 3:\n",
    "        value = 'alpha_3'\n",
    "        return value\n",
    "    else:\n",
    "        value = 'alpha_4'\n",
    "        return value\n",
    "\n",
    "\n",
    "df_title_region['alpha_code'] = df_title_region['region'].map(lambda x: alpha_code_check(x))\n",
    "print(df_title_region['alpha_code'].value_counts())\n",
    "df_title_region.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Great, now we have a new column that identifies the type of alpha code in that row.**\n",
    "\n",
    "**Let's now convert that to a country name using |pycountry|.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T02:10:50.811228Z",
     "start_time": "2020-06-22T02:10:50.386989Z"
    },
    "scrolled": true
   },
   "source": [
    "def country_alpha_converter(value):\n",
    "    '''This is a function to map columns and convert values of country alpha \n",
    "    codes to country names.'''\n",
    "    \n",
    "    if len(value) == 2:\n",
    "        x = pycountry.countries.get(alpha_2=value)\n",
    "        if x == None:\n",
    "            return 'None'\n",
    "        return x.name\n",
    "    elif len(value) == 3:\n",
    "        x = pycountry.countries.get(alpha_3=value)\n",
    "        if x == None:\n",
    "            return 'None'\n",
    "        return x.name\n",
    "    else:\n",
    "        x = pycountry.historic_countries.get(alpha_4=value) #old country codes\n",
    "        if x == None:\n",
    "            return 'None'\n",
    "        return x.name\n",
    "\n",
    "df_title_region['country'] = df_title_region['region'].map(lambda x: country_alpha_converter(x))\n",
    "df_title_region.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Looks good, though we can clearly see that there are lots of duplicates, as well as a 'None' in the country feature.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T02:10:56.432627Z",
     "start_time": "2020-06-22T02:10:56.345301Z"
    },
    "scrolled": true
   },
   "source": [
    "df_title_region[(df_title_region['alpha_code'] == 'alpha_3')\n",
    "                | \n",
    "                (df_title_region['alpha_code'] == 'alpha_4')\n",
    "               &\n",
    "               (df_title_region['country'] == 'None')].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Based on the information provided above, we can see that a lot of country_codes containing alpha_3 OR alpha_4 also have a 'None' value for their country feature, making these rows essentially useless for this analysis.  To proceed, we will drop all rows with the value of 'None' for the 'country' feature.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T02:11:01.523762Z",
     "start_time": "2020-06-22T02:11:01.477844Z"
    },
    "scrolled": false
   },
   "source": [
    "df_title_region = df_title_region[df_title_region['country'] != 'None']\n",
    "df_title_region.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T02:11:06.555400Z",
     "start_time": "2020-06-22T02:11:06.527517Z"
    },
    "scrolled": true
   },
   "source": [
    "df_title_region['alpha_code'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Looks like all of the alpha_3 codes went along with the 'none' values. Let's see what we have left for alpha_4 codes.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T02:11:11.565626Z",
     "start_time": "2020-06-22T02:11:11.538715Z"
    },
    "scrolled": false
   },
   "source": [
    "df_title_region[df_title_region['alpha_code'] == 'alpha_4']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As we can see above, the countries that were assigned alpha_4 codes are no longer officially recognized today.  For this analysis it is okay to remove these from our dataset.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T02:11:16.535165Z",
     "start_time": "2020-06-22T02:11:16.476729Z"
    },
    "scrolled": true
   },
   "source": [
    "df_title_region = df_title_region[df_title_region['alpha_code'] != 'alpha_4']\n",
    "df_title_region['alpha_code'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Great, now let's drop the alpha_code and region columns.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T02:11:21.485116Z",
     "start_time": "2020-06-22T02:11:21.467177Z"
    },
    "scrolled": true
   },
   "source": [
    "df_title_region = df_title_region.drop(['alpha_code', 'region'], axis=1)\n",
    "print(df_title_region.shape)\n",
    "df_title_region.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OK, so now we are only left with the duplicates. Let's drop them now so that later on our lists of countries (for our country_count feature) will be accurate. Let's also update the name of our DF as well.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T02:11:26.465083Z",
     "start_time": "2020-06-22T02:11:26.381626Z"
    },
    "scrolled": true
   },
   "source": [
    "df_title_country = df_title_region.drop_duplicates()\n",
    "print(df_title_country.shape)\n",
    "df_title_country.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dropped about 20K duplicates, very nice.  Now let's build out our feature containing a list of each country per movie.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T02:11:37.954408Z",
     "start_time": "2020-06-22T02:11:31.340330Z"
    },
    "scrolled": false
   },
   "source": [
    "df_title_countrylist = df_title_country.groupby('primary_title')['country'].apply(list).reset_index(name='country_list')\n",
    "print(df_title_countrylist.shape)\n",
    "df_title_countrylist.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We are now down to 114,284 rows, and with the cleaning that we have done up to this point, it seems fair to assume that all of these movies are unique, but just to be safe, lets check with the .value_counts() method.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T02:11:38.051401Z",
     "start_time": "2020-06-22T02:11:37.955377Z"
    },
    "scrolled": true
   },
   "source": [
    "df_title_countrylist['primary_title'].value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perfect!  Next we are going to make a simple feature that counts the number of countries each movie was released in.  This is easily achieved by calculating the length of the country_list feature for each movie using some nice list comprehension. Then update the DF name to be a bit more descriptive.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T02:11:38.055389Z",
     "start_time": "2020-06-22T02:11:38.052353Z"
    }
   },
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T02:11:38.504456Z",
     "start_time": "2020-06-22T02:11:38.056351Z"
    },
    "scrolled": true
   },
   "source": [
    "df_title_countrylist['country_count'] = [len(x) for x in df_title_countrylist['country_list']]\n",
    "df_title_countrylist_count = df_title_countrylist\n",
    "df_title_countrylist_count.to_csv(r'C:\\Users\\tcast\\Data Science Program\\Module 1\\Mod 1 Project - Movie Analysis\\Movie_Analysis\\Are movies more profitable if they are released in more countries\\CLEAN-title_countrylist_count.csv')\n",
    "# df_title_countrylist_count.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here we are going to subset the dataframe.  We are going to do so based on whether a movie was either a domestic or international release.  This significant because we will be able to compare these two different release types in the future should we have any questions involving the two.  We will create the domestic dataframe by filtering for movies whose country_count feature has a value of 1.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T02:11:38.554423Z",
     "start_time": "2020-06-22T02:11:38.506141Z"
    },
    "scrolled": true
   },
   "source": [
    "df_domestic_title_country = df_title_countrylist_count[\n",
    "    df_title_countrylist_count[\n",
    "        'country_count'\n",
    "    ] == 1\n",
    "]\n",
    "\n",
    "df_domestic_title_country = df_domestic_title_country.drop('country_count', axis=1)\n",
    "# Reassigned variable to avoid 'A value is trying to be set on a copy of a slice from a DataFrame.' error.\n",
    "df_domestic_title_country['country_list'] = df_domestic_title_country['country_list'].map(lambda x: ''.join(x))\n",
    "df_domestic_title_country.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Great, now we can see all of the domestic movie releases. If we want to, we can also group this dataframe by its country feature and create a list of domestic movies released in each one respectively.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T02:11:38.597265Z",
     "start_time": "2020-06-22T02:11:38.555377Z"
    },
    "scrolled": true
   },
   "source": [
    "df_domestic_country_movie_list = df_domestic_title_country.groupby('country_list')['primary_title'].apply(list).reset_index(name='movie_list')\n",
    "df_domestic_country_movie_list.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Or we can just see how many domestic movies per country without a list of titles.  We can rearrange this as needed to prepare for a future merge or join with another dataset.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T02:11:38.615246Z",
     "start_time": "2020-06-22T02:11:38.598261Z"
    }
   },
   "source": [
    "df_dom_movies_per_country = df_domestic_title_country\n",
    "df_dom_movies_per_country['movies_per_country'] = 1\n",
    "df_dom_movies_per_country = df_domestic_title_country.groupby('country_list').sum()\n",
    "df_dom_movies_per_country.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now we are going to create out dataframe of international movies, those with more than 1 in their country_count feature.\n",
    "We then reset the index just to make it look nicer, and to lessen any potential merge or join issues later.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T02:11:38.631175Z",
     "start_time": "2020-06-22T02:11:38.616214Z"
    }
   },
   "source": [
    "df_int_title_clist_ccount = df_title_countrylist_count[\n",
    "    df_title_countrylist_count[\n",
    "        'country_count'\n",
    "    ] > 1\n",
    "]\n",
    "\n",
    "df_int_title_clist_ccount = df_int_title_clist_ccount.reset_index().drop('index', axis=1)\n",
    "df_int_title_clist_ccount.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning & Converting - Domestic & International Budgets/Revenues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's have a loser look at this dataset and see if anything stands out.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T02:12:18.648155Z",
     "start_time": "2020-06-22T02:12:18.639222Z"
    },
    "scrolled": false
   },
   "source": [
    "print(df_movie_moneys.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T02:12:23.639090Z",
     "start_time": "2020-06-22T02:12:23.628119Z"
    },
    "scrolled": true
   },
   "source": [
    "df_movie_moneys.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's drop the 'id' column here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T02:12:28.630776Z",
     "start_time": "2020-06-22T02:12:28.620776Z"
    }
   },
   "source": [
    "df_movie_moneys = df_movie_moneys.drop('id', axis=1)\n",
    "df_movie_moneys.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clean and convert the 'production_budget', 'domestic_gross', and 'worldwide_gross' columns from strings to floats using the function created below**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T02:12:33.720250Z",
     "start_time": "2020-06-22T02:12:33.686792Z"
    },
    "scrolled": false
   },
   "source": [
    "def string_to_float_converter(value, to_replace=None, new_value='', new_dtype=float):\n",
    "    \n",
    "    '''This function cleans and converts any column of strings with UP TO 3\n",
    "    variables at a time. This function is designed to be mapped along columns\n",
    "    in a Pandas DataFrame and takes in a (value) and the desired string characters\n",
    "    to be replacesd (to_replace). By default, new_value is: '' and new_dtype \n",
    "    is: 'float', though they may be changed as required.\n",
    "    \n",
    "    Returns:\n",
    "    A cleaned and converted value.\n",
    "    \n",
    "    Example: \n",
    "    df['col'].map(lambda x: string_to_float_converter(x, ['$',',','&']))''' \n",
    "    \n",
    "    if type(to_replace) == list:\n",
    "        n = len(to_replace)\n",
    "        if n == 2:\n",
    "            return new_dtype(value.replace(to_replace[0], new_value).replace(to_replace[1], new_value))\n",
    "        if n == 3:\n",
    "            return new_dtype(value.replace(to_replace[0], new_value).replace(to_replace[1], new_value).replace(to_replace[2]))\n",
    "    else:\n",
    "        return new_dtype(value.replace(to_replace, new_value))\n",
    "\n",
    "df_movie_moneys['worldwide_gross'] = df_movie_moneys['worldwide_gross'].map(lambda x: string_to_float_converter(x, to_replace=['$',',']))\n",
    "df_movie_moneys['production_budget'] = df_movie_moneys['production_budget'].map(lambda x: string_to_float_converter(x, to_replace=['$',',']))\n",
    "df_movie_moneys['domestic_gross'] = df_movie_moneys['domestic_gross'].map(lambda x: string_to_float_converter(x, to_replace=['$',',']))\n",
    "\n",
    "df_movie_moneys.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert the 'release_date' column to pandas datetime objects.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T02:12:39.279670Z",
     "start_time": "2020-06-22T02:12:38.738526Z"
    },
    "scrolled": true
   },
   "source": [
    "df_movie_moneys['release_date'] = pd.to_datetime(df_movie_moneys['release_date'])\n",
    "df_movie_moneys.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Excellent, now let's have a closer look at our numeric columns.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T02:12:44.411132Z",
     "start_time": "2020-06-22T02:12:44.393651Z"
    },
    "scrolled": true
   },
   "source": [
    "print(df_movie_moneys.shape)\n",
    "df_movie_moneys.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lots to see here.  The first thing to notice is the 0 values in the 'domestic_gross' and 'worldwide_gross' columns.  Let's have a look at what kinds of movies fit this criteria before we decide how to proceed.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T02:12:49.559534Z",
     "start_time": "2020-06-22T02:12:49.482194Z"
    }
   },
   "source": [
    "print(df_movie_moneys[(df_movie_moneys['worldwide_gross'] == 0)\n",
    "                                  |\n",
    "                                  (df_movie_moneys['domestic_gross'] == 0)].shape)\n",
    "df_movie_moneys[(df_movie_moneys['worldwide_gross'] == 0)\n",
    "                                  |\n",
    "                                  (df_movie_moneys['domestic_gross'] == 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If we sort by 'release_date' then we can see that some of these movies have not even been released yet.  Furthermore, there are release dates that have since passed and yet these movies still have no financial information.  Finally we have some examples of movies where they have a 'worldwide_gross' figure, yet no 'domestic_gross' figure.  I can think of no good, or logical reason as to why this may be the case other than error in the data, therefore we will drop these rows.  This constitutes a drop of 10% of our data, though it is likely that most of these movies we did not have country information for either.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T02:12:54.540141Z",
     "start_time": "2020-06-22T02:12:54.515191Z"
    },
    "scrolled": true
   },
   "source": [
    "df_movie_moneys = df_movie_moneys[(df_movie_moneys['worldwide_gross'] != 0)\n",
    "                                  &\n",
    "                                  (df_movie_moneys['domestic_gross'] != 0)]\n",
    "print(df_movie_moneys.describe())\n",
    "print(df_movie_moneys.shape)\n",
    "df_movie_moneys.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finally, lets's change the feature name from 'movie' to 'primary_title' so as to make future merges less stressful!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T02:12:59.594844Z",
     "start_time": "2020-06-22T02:12:59.538485Z"
    },
    "scrolled": false
   },
   "source": [
    "df_movie_moneys = df_movie_moneys.rename(columns={'movie':'primary_title'})\n",
    "df_movie_moneys.to_csv(r'C:\\Users\\tcast\\Data Science Program\\Module 1\\Mod 1 Project - Movie Analysis\\Movie_Analysis\\Are movies more profitable if they are released in more countries\\CLEAN-BOM_budget_revenues.csv')\n",
    "df_movie_moneys.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We have left the rest of the outlier data in for now so that we can have a better look at the data through EDA before determining the best method of dealing with them.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration, Feature Engineering, and Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bringing the data together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The first step in our Data Exploration & Feature Engineering Phase will be to bring our data together and start to have a look at what stands out.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T02:13:04.884409Z",
     "start_time": "2020-06-22T02:13:04.855487Z"
    },
    "scrolled": true
   },
   "source": [
    "df_int_movies_analysis_inner = df_movie_moneys.merge(df_int_title_clist_ccount, on='primary_title')\n",
    "print(df_int_movies_analysis_inner.shape)\n",
    "df_int_movies_analysis_inner.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering - Adding more metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Foreign Gross, Net Revenue, and Return on Investment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Great! We are now down to our ~1800 rows.  This is less than half of the original 'bom_movies_gross' data set but we now have a lot more accurate information about each movie.  Before we look at any relationships, let's add a few more important features to this dataset.  Our question is surrounding profitability so it makes sense to add in features related to that measurement.  Let's add a foreign_gross', 'net_revenue', and 'return_on_investment' each to this dataset.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T02:13:10.377170Z",
     "start_time": "2020-06-22T02:13:10.358219Z"
    },
    "scrolled": true
   },
   "source": [
    "df_int_movies_analysis_inner['foreign_gross'] = df_int_movies_analysis_inner[\n",
    "    'worldwide_gross'] - df_int_movies_analysis_inner['domestic_gross']\n",
    "\n",
    "df_int_movies_analysis_inner['net_revenue'] = df_int_movies_analysis_inner[\n",
    "    'worldwide_gross'] - df_int_movies_analysis_inner['production_budget']\n",
    "\n",
    "df_int_movies_analysis_inner['return_on_investment'] = (\n",
    "    (df_int_movies_analysis_inner[\n",
    "        'worldwide_gross'] - df_int_movies_analysis_inner[\n",
    "        'production_budget'])/df_int_movies_analysis_inner[\n",
    "        'production_budget'])\n",
    "\n",
    "df_int_movies_analysis_inner.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add profit/loss feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T02:13:15.476378Z",
     "start_time": "2020-06-22T02:13:15.471368Z"
    }
   },
   "source": [
    "def profit_loss_function(ROI):\n",
    "    \n",
    "    '''This function takes in an ROI and determins if it value constitues a \n",
    "    profit or a loss on a particular investment.\n",
    "    \n",
    "    Returns:\n",
    "    str 'profit' or 'loss'\n",
    "    \n",
    "    Eg:\n",
    "    INPUT:\n",
    "    profit_loss_function(1.5)\n",
    "    \n",
    "    OUTPUT:\n",
    "    'profit'\n",
    "    '''\n",
    "    \n",
    "    if ROI == 0:\n",
    "        x = 'break-even'\n",
    "    if ROI > 0:\n",
    "        x = 'profit'\n",
    "    else:\n",
    "        x = 'loss'\n",
    "    return x\n",
    "        \n",
    "df_int_movies_analysis_inner['profit/loss'] = df_int_movies_analysis_inner['return_on_investment'].map(lambda x: profit_loss_function(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Category Feature - Country Bins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T02:36:09.492817Z",
     "start_time": "2020-06-22T02:36:09.227484Z"
    }
   },
   "source": [
    "def country_count_category(value):\n",
    "    '''This function is meant to be mapped along a DataFrame series.  It is \n",
    "    specifically meant to take in a country_count value from a dataframe and \n",
    "    assigns it to the appropriate category.  These categories can be \n",
    "    manipulated as needed, see the commented out potential changes below.\n",
    "    \n",
    "    Returns:\n",
    "    Assigned categorical value\n",
    "    \n",
    "    Example:\n",
    "    df['country_count'].map(lambda x: country_count_category(x))'''\n",
    "    \n",
    "    if value <=10:\n",
    "        value = '2 - 10'\n",
    "    elif value > 10 and value <= 20:\n",
    "        value = '11 - 20'\n",
    "    elif value > 20 and value <= 30:\n",
    "        value = '21 - 30'\n",
    "    elif value > 30 and value <= 40:\n",
    "        value = '31 - 40'\n",
    "    else: \n",
    "#         value > 40 and value <= 50:\n",
    "        value = '41 +'\n",
    "#     elif value > 50 and value <= 60:\n",
    "#         value = '51 - 60'\n",
    "#     else: \n",
    "#         value = '61 +'\n",
    "    return value\n",
    "    \n",
    "df_int_movies_analysis_inner['country_count_category'] = df_int_movies_analysis_inner['country_count'].map(lambda x: country_count_category(x))\n",
    "df_int_movies_analysis_inner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  **That was easy! Now that we have the features that we would liketo see, let's start out with Seaborn's .pairplot and see what kinds of relationships exist.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pairplot - Initial Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T02:13:37.807371Z",
     "start_time": "2020-06-22T02:13:25.813144Z"
    },
    "scrolled": false
   },
   "source": [
    "sns.set(context='notebook', style='darkgrid', color_codes=True, palette='muted')\n",
    "\n",
    "sns.pairplot(df_int_movies_analysis_inner, kind='reg');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is great! On our first look we can already see that a positive relationship exists between 'country_count' and our gross figures. Though remember, our question is interested in profitability, not just revenue. The last column on the above matrix shows a very wide range of potential profitability, however the direction that is it going is great! We also observe that there are A LOT of positively-skewed features for budget and revenue distributions.**\n",
    "\n",
    "**Next, let's take a closer look at our individual features using a boxplot to help us better contextualize the outliers.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boxplot - Outlier Identification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T02:13:43.158642Z",
     "start_time": "2020-06-22T02:13:42.819367Z"
    },
    "scrolled": false
   },
   "source": [
    "fig, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(ncols=5, figsize=(15,10), sharey=True)\n",
    "\n",
    "ax_list = [ax1, ax2, ax3, ax4, ax5]\n",
    "x = [df_int_movies_analysis_inner['production_budget'],\n",
    "     df_int_movies_analysis_inner['domestic_gross'],\n",
    "     df_int_movies_analysis_inner['worldwide_gross'],\n",
    "     df_int_movies_analysis_inner['foreign_gross'],\n",
    "     df_int_movies_analysis_inner['net_revenue']]\n",
    "\n",
    "\n",
    "for n in range(1,6):\n",
    "    ax = ax_list[n-1]\n",
    "    x_new = x[n-1]\n",
    "    sns.set_style('darkgrid')\n",
    "    sns.boxplot(x_new, ax=ax, orient='v')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Whoa! Looks like the data here are littered with outliers on the positive end of the spectrum.  Let's try a few different techniques and see which ones result in a more normalized distribution!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier Exploration & Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's create a new dataframe to use for the following EDA purposes since we have so many outliers in our original dataset.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T02:13:48.219299Z",
     "start_time": "2020-06-22T02:13:48.200392Z"
    },
    "scrolled": false
   },
   "source": [
    "df_int_movies_analysis_inner_cleaned = df_int_movies_analysis_inner.copy()\n",
    "print(df_int_movies_analysis_inner_cleaned.shape)\n",
    "df_int_movies_analysis_inner_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The feature that looks like it contains the most egregious amount of outliers is 'worldwide_gross'. Let's see how the data are affected when we start to preform some outlier cleaning in the cell below.  Let's write a function in the following cell that will take in information about how we want to adjust our dataframe using quantiles. This function will allow us to perform quick EDA, and if we see something that we like, we can just re-define a new dataframe as needed.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Function - Quantile Column Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T02:13:53.705107Z",
     "start_time": "2020-06-22T02:13:53.449272Z"
    },
    "scrolled": true
   },
   "source": [
    "def between_quantile_col_cleaner(df, colname, lower_quantile, upper_quantile):\n",
    "    \n",
    "    '''This function\\'s purpose is to address outliers in data.  This funciton\n",
    "    takes in a dataframe, column name, and both lower/upper quantiles to keep\n",
    "    data using the .between method.\n",
    "    \n",
    "    Returns:\n",
    "    Dataframe\n",
    "    \n",
    "    Example:\n",
    "    between_quantile_cleaner(df_cars, 'type', 0.05, 0.95)'''\n",
    "    \n",
    "    column_total = df[colname]\n",
    "    \n",
    "    column_remaining = column_total.between(\n",
    "        column_total.quantile\n",
    "        (\n",
    "            lower_quantile\n",
    "        ),\n",
    "        column_total.quantile\n",
    "        (\n",
    "            upper_quantile\n",
    "        ))\n",
    "    df = df.iloc[column_remaining[column_remaining].index]\n",
    "    print(df.shape)\n",
    "    return df\n",
    "\n",
    "between_quantile_col_cleaner(df_int_movies_analysis_inner_cleaned, 'worldwide_gross', .10, .90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funtion - Quantile Column Cleaning (Removed Rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here is a function that shows us the movies that were dropped.  This is a useful function as it allows us to see which movies don't make the cleaning-cut!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T02:13:58.942403Z",
     "start_time": "2020-06-22T02:13:58.749916Z"
    },
    "scrolled": true
   },
   "source": [
    "def between_quantile_col_removed(df, colname, lower_quantile, upper_quantile):\n",
    "    \n",
    "    '''This function\\'s purpose is to address outliers in data.  This funciton\n",
    "    takes in a dataframe, column name, and both lower/upper quantiles to keep\n",
    "    data using the .between method.\n",
    "    \n",
    "    Returns:\n",
    "    Dataframe\n",
    "    \n",
    "    Example:\n",
    "    between_quantile_cleaner(df_cars, 'type', 0.05, 0.95)'''\n",
    "    \n",
    "    column_total = df[colname]\n",
    "    \n",
    "    column_remaining = column_total.between(\n",
    "        column_total.quantile\n",
    "        (\n",
    "            lower_quantile\n",
    "        ),\n",
    "        column_total.quantile\n",
    "        (\n",
    "            upper_quantile\n",
    "        ))\n",
    "    df = df.drop(column_remaining[column_remaining].index)\n",
    "    print(df.shape)\n",
    "    return df\n",
    "\n",
    "between_quantile_col_removed(df_int_movies_analysis_inner_cleaned, 'worldwide_gross', .10, .90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boxplot - Box Office Numbers w/ Outlier Manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Ok, let's have a look at our data now using our new function and see how the below plots change. The data between the 10th and 90th percentile looks the most reasonable for this visualization.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T02:20:59.375643Z",
     "start_time": "2020-06-22T02:20:59.025582Z"
    },
    "scrolled": false
   },
   "source": [
    "df_int_movies_analysis_inner_cleaned_boxtest = between_quantile_col_cleaner(\n",
    "    df_int_movies_analysis_inner_cleaned,\n",
    "    'worldwide_gross',\n",
    "    .10,\n",
    "    .90)\n",
    "\n",
    "fig, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(ncols=5, sharey=True, figsize=(15,10))\n",
    "\n",
    "ax_list = [ax1, ax2, ax3, ax4, ax5]\n",
    "x = [df_int_movies_analysis_inner_cleaned_boxtest['production_budget'],\n",
    "     df_int_movies_analysis_inner_cleaned_boxtest['domestic_gross'],\n",
    "     df_int_movies_analysis_inner_cleaned_boxtest['worldwide_gross'],\n",
    "     df_int_movies_analysis_inner_cleaned_boxtest['foreign_gross'],\n",
    "     df_int_movies_analysis_inner_cleaned_boxtest['net_revenue']]\n",
    "\n",
    "for n in range(1,6):\n",
    "    ax = ax_list[n-1]\n",
    "    x_new = x[n-1]\n",
    "    sns.set_style('darkgrid');\n",
    "    sns.boxplot(x_new, ax=ax, orient='v', showmeans=True, color='lightpink');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Countplot - Countries Per Movie w/ Outlier Manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now lets do the same testing but with a countplot.  This visual looks quite similar regardless of the manner with which it was sliced.  Therefore the full dataset was chosen for the best representation of this visual.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T02:19:48.131772Z",
     "start_time": "2020-06-22T02:19:47.714381Z"
    },
    "scrolled": false
   },
   "source": [
    "df_int_movies_analysis_inner_cleaned_histtest = df_int_movies_analysis_inner_cleaned\n",
    "\n",
    "# between_quantile_col_cleaner(\n",
    "#     df_int_movies_analysis_inner_cleaned,\n",
    "#     'worldwide_gross',\n",
    "#     .10,\n",
    "#     .90)\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "column = df_int_movies_analysis_inner_cleaned_histtest['country_count']\n",
    "\n",
    "sns.countplot(x=column,\n",
    "              data=df_int_movies_analysis_inner_cleaned_histtest,\n",
    "              saturation=2,\n",
    "              palette=\"rocket\");\n",
    "\n",
    "plt.ylabel('Number of Movies', fontsize=23)\n",
    "plt.xlabel('Number of Countries', fontsize=23)\n",
    "plt.title('Countries Per Movie - Countplot Distribution', fontsize=30, pad=10, loc='right');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Microsoft Question Visualization & Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Okay, now for the last step.  We have seen above how the data can change depending on how we treat our outliers.  Let's now aim to answer the big question:**\n",
    "\n",
    "**Are movies that are released in more countries more profitable?**\n",
    "\n",
    "**Let's create two more plots and put them side by side.  The firs plot will look at the costs of producing these movies, as well as how much money the tend to bring back in.  The second plot will look at the number of movies that come out of the international scene with either a profit or a loss.  The following plots will use the MEDIAN as its estimator fucntion as it is the best tool we have to combat against the many outliers that remain.**\n",
    "\n",
    "**These last two visualizations will be shown using the data from the 1st to 99th percentile. There were some variations in the plotting depending on how the dataset was sliced, but the reasons were mostly due to not having a large sample size of movies in over 40 coutnries.  Therefore we chose to stick with the subset below in the end.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T02:25:13.286983Z",
     "start_time": "2020-06-22T02:25:12.938906Z"
    },
    "scrolled": false
   },
   "source": [
    "df_int_movies_analysis_inner_cleaned_bartest = between_quantile_col_cleaner(\n",
    "    df_int_movies_analysis_inner_cleaned,\n",
    "    'worldwide_gross',\n",
    "    .01,\n",
    "    .99)\n",
    "\n",
    "fig = plt.figure(figsize=(18,10));\n",
    "sns.set(style='darkgrid');\n",
    "order = ['2 - 10', '11 - 20', '21 - 30', '31 - 40', '41 +']\n",
    "#  - 50', '51 - 60', '61 +'\n",
    "\n",
    "ax1 = fig.add_subplot(121)\n",
    "\n",
    "sns.set_color_codes('pastel')\n",
    "sns.pointplot(x='country_count_category',\n",
    "            y='worldwide_gross',\n",
    "            data=df_int_movies_analysis_inner_cleaned_bartest,\n",
    "            color='b',\n",
    "            order=order,\n",
    "            estimator=np.median,\n",
    "            ax=ax1,\n",
    "            ci=None);\n",
    "\n",
    "sns.set_color_codes('pastel')\n",
    "sns.pointplot(x='country_count_category',\n",
    "            y='net_revenue',\n",
    "            data=df_int_movies_analysis_inner_cleaned_bartest,\n",
    "            color='g',\n",
    "            order=order,\n",
    "            estimator=np.median,\n",
    "            ax=ax1,\n",
    "            ci=None);\n",
    "\n",
    "sns.set_color_codes('muted')\n",
    "sns.pointplot(x='country_count_category',\n",
    "            y='production_budget',\n",
    "            data=df_int_movies_analysis_inner_cleaned_bartest,\n",
    "            color='r',\n",
    "            order=order,\n",
    "            estimator=np.median,\n",
    "            ax=ax1,\n",
    "            ci=None);\n",
    "\n",
    "plt.title('International Movie Costs vs. Revenues ', fontsize=25, loc='center', pad=15);\n",
    "plt.legend(['Worldwide Gross', 'Net Revenue', 'Production Budget'], frameon=False, fontsize=17, loc='upper left');\n",
    "plt.ylabel('Hundreds of Millions (Median)', fontsize=22);\n",
    "plt.xlabel('Number of Country Releases', fontsize=20);\n",
    "plt.xticks(fontsize=18);\n",
    "plt.yticks(fontsize=18);\n",
    "\n",
    "ax2 = fig.add_subplot(122)\n",
    "\n",
    "# sns.set_color_codes('pastel')\n",
    "# sns.barplot(x='country_count_category',\n",
    "#             y='foreign_gross',\n",
    "#             data=df_int_movies_analysis_inner_cleaned_bartest,\n",
    "#             color='orange',\n",
    "#             order=order,\n",
    "#             estimator=np.median,\n",
    "#             ax=ax2,\n",
    "#             ci=None);\n",
    "\n",
    "sns.barplot(x='country_count_category',\n",
    "            y='return_on_investment',\n",
    "            data=df_int_movies_analysis_inner_cleaned_bartest,\n",
    "            order=order,\n",
    "            estimator=np.median,\n",
    "            ax=ax2,\n",
    "            ci=None,\n",
    "            saturation=20,\n",
    "            hue='profit/loss',\n",
    "            hue_order=['loss', 'profit']);\n",
    "\n",
    "# sns.set_color_codes('pastel')\n",
    "# sns.pointplot(x='country_count_category',\n",
    "#             y='net_revenue',\n",
    "#             data=df_int_movies_analysis_inner_cleaned_bartest,\n",
    "#             color='darkgreen',\n",
    "#             order=order,\n",
    "#             estimator=np.median,\n",
    "#             ax=ax2,\n",
    "#             ci=None);\n",
    "\n",
    "plt.title('International Profits vs. Losses', fontsize=25, loc='right', pad=15);\n",
    "plt.legend(['Loss', 'Profit'], frameon=False, fontsize=20, loc='upper left');\n",
    "plt.ylabel('Return on Investment (Median)', fontsize=22);\n",
    "plt.xlabel('Number of Country Releases', fontsize=20);\n",
    "plt.xticks(fontsize=18);\n",
    "plt.yticks(fontsize=18);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**These last two visualizations paint the picture quite clearly that in fact yes, movies that are released in more countries are generally more profitable.  We can also make some conclusions about the risks involved in making movies that are meant to be for a global audience.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# * * Bonus * * - \"Domestic\" Movie Country Count Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As we can see below, the IMDB database was not as accurate as we would have liked.  Avatar is still the largest movie ever made in almost all aspects, yet it has a country list consisting only of Japan.  We thought it would be interesting to see, based on the cleaning of the previous data, if we could predict the number of movies that a country was released in based on its financial metrics.  Below we have made a function to check against the 'worldwide_gross' value, though this function could easily be altered to measure against any of the numerical features.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T02:14:20.267769Z",
     "start_time": "2020-06-22T02:14:20.221891Z"
    },
    "scrolled": false
   },
   "source": [
    "df_domestic_country_check = df_movie_moneys.merge(df_domestic_title_country, on='primary_title')\n",
    "\n",
    "df_domestic_country_check = df_domestic_country_check.sort_values('worldwide_gross', ascending=False)\n",
    "\n",
    "df_domestic_country_check['return_on_investment'] = (\n",
    "    (df_domestic_country_check['worldwide_gross'] - \n",
    "     df_domestic_country_check['production_budget']) / \n",
    "    df_domestic_country_check['production_budget'])\n",
    "\n",
    "df_domestic_country_check['profit/loss'] = df_domestic_country_check[\n",
    "    'return_on_investment'].map(lambda x: profit_loss_function(x))\n",
    "\n",
    "df_domestic_country_check['foreign_gross'] = df_domestic_country_check[\n",
    "    'worldwide_gross'] - df_domestic_country_check['domestic_gross']\n",
    "\n",
    "df_int_movies_analysis_inner['net_revenue'] = df_int_movies_analysis_inner[\n",
    "    'worldwide_gross'] - df_int_movies_analysis_inner['production_budget']\n",
    "\n",
    "df_domestic_country_check.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T02:14:25.257456Z",
     "start_time": "2020-06-22T02:14:25.243446Z"
    }
   },
   "source": [
    "df_int_movies_analysis_inner_cleaned.groupby('country_count_category').median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The function below is based on the above table, replace the values as needed to switch between features to compare.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T02:14:35.506958Z",
     "start_time": "2020-06-22T02:14:35.498955Z"
    }
   },
   "source": [
    "def domestic_movie_guess(movie):\n",
    "    \n",
    "    '''This function takes in the name of a movie (string) from the \n",
    "    df_domestic_country_check dataset and returns an estimate of the number of\n",
    "    countries that the movie was released in.'''\n",
    "    \n",
    "    dom_df = df_domestic_country_check\n",
    "    int_df = df_int_movies_analysis_inner_cleaned\n",
    "    \n",
    "    country_prob_list = df_int_movies_analysis_inner_cleaned.groupby('country_count_category').median()['worldwide_gross']\n",
    "#     print(country_prob_list)\n",
    "    \n",
    "    country_prob_list_keys = list(country_prob_list.keys())\n",
    "#     print(country_prob_list_keys)\n",
    "    \n",
    "    country_prob_list_values = list(country_prob_list.unique())\n",
    "#     print(country_prob_list_values)\n",
    "    \n",
    "    prob_dict = {}\n",
    "    \n",
    "#     for i in country_prob_list_values:\n",
    "#         prob_dict[i] = country_prob_list_values[i]\n",
    "    prob_dict['7263222.0'] = '10 or less'\n",
    "    prob_dict['13019253.0'] = '11 - 20'\n",
    "    prob_dict['70671126.0'] = '21 - 30'\n",
    "    prob_dict['260002115.0'] = '31 - 40'\n",
    "    prob_dict['899906806.5'] = '41 +'\n",
    "#     print(prob_dict)\n",
    "    \n",
    "    worldwide_gross = int(dom_df[dom_df['primary_title'] == movie]['worldwide_gross'].unique())\n",
    "#     print(worldwide_gross)\n",
    "\n",
    "    for i in country_prob_list_values:\n",
    "        n = 0\n",
    "        if worldwide_gross > country_prob_list_values[-1]:\n",
    "            return country_prob_list_keys[-1]\n",
    "        elif i < worldwide_gross:\n",
    "#             print('passed')\n",
    "            continue\n",
    "        else:\n",
    "            return print('Hmmmm, I\\'m thinking this movie was released in {} countries.'.format(prob_dict[str(i)]))\n",
    "        \n",
    "    \n",
    "domestic_movie_guess('Cast Away')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feel free to check out your favourite  movie source online to compare the results!** "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "437.167px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
